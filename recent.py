# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QoUG-lt-qoowxRF2uYrQM1qF1h4cZ8m1
"""

import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from keras.models import Sequential
from keras.layers import Dense, LSTM
import streamlit as st

# Function to fetch data from Yahoo Finance
def fetch_data(tickers, start, end):
    try:
        data = yf.download(tickers, start=start, end=end)
        available_tickers = data.columns.levels[1]
        unavailable_tickers = [ticker for ticker in tickers if ticker not in available_tickers]
        data = data['Adj Close']
        return data, unavailable_tickers
    except Exception as e:
        st.error(f"Error fetching data: {e}")
        return None, tickers

# Function to train and evaluate models
def train_and_evaluate_models(X_train, X_test, y_train, y_test):
    models = {
        'Linear Regression': LinearRegression(),
        'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),
        'LSTM': Sequential([
            LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),
            LSTM(50, return_sequences=False),
            Dense(25),
            Dense(y_train.shape[1])
        ])
    }

    rmse_scores = {}

    # Linear Regression and Random Forest
    for name, model in models.items():
        if name != 'LSTM':
            model.fit(X_train.reshape(X_train.shape[0], -1), y_train)
            y_pred = model.predict(X_test.reshape(X_test.shape[0], -1))
            rmse = np.sqrt(mean_squared_error(y_test, y_pred))
            rmse_scores[name] = rmse

    # LSTM Model
    X_train_lstm = X_train
    X_test_lstm = X_test
    models['LSTM'].compile(optimizer='adam', loss='mean_squared_error')
    models['LSTM'].fit(X_train_lstm, y_train, epochs=5, batch_size=1, verbose=1)
    y_pred_lstm = models['LSTM'].predict(X_test_lstm)
    rmse_scores['LSTM'] = np.sqrt(mean_squared_error(y_test, y_pred_lstm))

    best_model_name = min(rmse_scores, key=rmse_scores.get)
    best_model = models[best_model_name]

    return best_model, best_model_name, rmse_scores

# Function to simulate portfolios and calculate metrics
def simulate_portfolios(mean_returns, cov_matrix, num_portfolios=10000, risk_free_rate=0.01):
    results = np.zeros((3, num_portfolios))
    weights_record = []

    for i in range(num_portfolios):
        weights = np.random.random(len(mean_returns))
        weights /= np.sum(weights)

        portfolio_return = np.sum(weights * mean_returns) * 252
        portfolio_std_dev = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights))) * np.sqrt(252)
        sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_std_dev

        results[0, i] = portfolio_return
        results[1, i] = portfolio_std_dev
        results[2, i] = sharpe_ratio
        weights_record.append(weights)

    return results, weights_record

# Main Function
def main():
    st.title("Stock Portfolio Optimization")

    # User input for stock tickers
    tickers = st.text_input("Enter stock tickers separated by commas").split(',')
    tickers = [ticker.strip() for ticker in tickers]

    if st.button("Fetch Data"):
        # Fetch historical stock price data
        data, unavailable_tickers = fetch_data(tickers, start="2000-01-01", end="2023-01-01")

        if unavailable_tickers:
            st.error(f"The ticker(s) {', '.join(unavailable_tickers)} you entered is not available for analysis. Please enter the appropriate ticker(s).")
            return
        elif data is None or data.empty:
            st.error("No data fetched for the given tickers. Please enter the appropriate ticker(s).")
            return

        # Plot historical stock prices
        st.subheader('Historical Stock Prices')
        st.line_chart(data)

        # Calculate daily returns
        returns = data.pct_change().dropna()

        if returns.empty:
            st.error("No returns data available. Please enter valid tickers.")
            return

        # Summary statistics
        st.subheader('Summary Statistics')
        st.write(returns.describe())

        # Plot return distributions
        st.subheader('Return Distributions')
        st.line_chart(returns)

        # Correlation matrix
        st.subheader('Correlation Matrix')
        st.write(returns.corr())

        # Generate a heatmap of the correlation matrix
        st.subheader('Correlation Matrix Heatmap')
        fig, ax = plt.subplots()
        sns.heatmap(returns.corr(), annot=True, cmap='coolwarm', linewidths=0.5, ax=ax)
        st.pyplot(fig)

        # Train and evaluate models
        X = returns[:-1].values
        y = returns.shift(-1).dropna().values

        # Reshape X and y for LSTM
        X = X.reshape(X.shape[0], X.shape[1], 1)
        y = y.reshape(y.shape[0], y.shape[1])

        # Train-test split
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

        best_model, best_model_name, rmse_scores = train_and_evaluate_models(X_train, X_test, y_train, y_test)
        st.subheader(f"Best model: {best_model_name}")
        st.write(f"RMSE Scores: {rmse_scores}")

        # Make predictions using the best model
        if best_model_name == 'LSTM':
            predicted_returns = pd.Series(best_model.predict(X_test)[-1], index=tickers)
        else:
            predicted_returns = pd.Series(best_model.predict(X_test.reshape(X_test.shape[0], -1))[-1], index=tickers)

        # Simulate portfolios based on predicted returns
        mean_returns_pred = predicted_returns  # Use predicted returns directly
        cov_matrix_pred = returns.cov()
        results_pred, weights_record_pred = simulate_portfolios(mean_returns_pred, cov_matrix_pred)

        # Convert results array to Pandas DataFrame
        results_frame_pred = pd.DataFrame(results_pred.T, columns=['Return', 'Standard Deviation', 'Sharpe Ratio'])

        # Locate the portfolio with the maximum Sharpe ratio
        max_sharpe_idx_pred = results_frame_pred['Sharpe Ratio'].idxmax()
        max_sharpe_port_pred = results_frame_pred.iloc[max_sharpe_idx_pred]
        max_sharpe_weights_pred = weights_record_pred[max_sharpe_idx_pred]

        # Locate the portfolio with the minimum standard deviation
        min_vol_idx_pred = results_frame_pred['Standard Deviation'].idxmin()
        min_vol_port_pred = results_frame_pred.iloc[min_vol_idx_pred]
        min_vol_weights_pred = weights_record_pred[min_vol_idx_pred]

        st.subheader("\nPredicted Maximum Sharpe Ratio Portfolio Allocation\n")
        st.write(f"Annualized Return: {max_sharpe_port_pred[0]}")
        st.write(f"Annualized Standard Deviation: {max_sharpe_port_pred[1]}")
        st.write(f"Sharpe Ratio: {max_sharpe_port_pred[2]}")
        st.write(f"Weights: {max_sharpe_weights_pred}")

        st.subheader("\nPredicted Minimum Volatility Portfolio Allocation\n")
        st.write(f"Annualized Return: {min_vol_port_pred[0]}")
        st.write(f"Annualized Standard Deviation: {min_vol_port_pred[1]}")
        st.write(f"Sharpe Ratio: {min_vol_port_pred[2]}")
        st.write(f"Weights: {min_vol_weights_pred}")

        # Plot the predicted efficient frontier
        st.subheader('Predicted Efficient Frontier')
        fig, ax = plt.subplots()
        scatter = ax.scatter(results_frame_pred['Standard Deviation'], results_frame_pred['Return'], c=results_frame_pred['Sharpe Ratio'], cmap='viridis')
        ax.set_xlabel('Annualized Standard Deviation')
        ax.set_ylabel('Annualized Return')
        fig.colorbar(scatter, label='Sharpe Ratio')
        st.pyplot(fig)

if __name__ == "__main__":
    main()